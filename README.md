# The OG Machine Learning Itenary

A structured table of contents for learning key algorithms and concepts, designed for creating notebooks to study step-by-step.

1. **Bayesian Probability**
   - Understand priors, likelihoods, and posteriors.
   - Learn Bayes' theorem for updating probabilities with new evidence.
   - Example: Predicting rain based on cloud observations.

2. **Naive Bayes Classifier**
   - Explore the independence assumption for features.
   - Study how it calculates probabilities for classification.
   - Applications: Spam email detection, sentiment analysis.

3. **Logistic Regression**
   - Master the sigmoid function for binary outcomes (0-1 probabilities).
   - Learn how weights and biases adjust to fit data.
   - Use cases: Fraud detection, medical diagnosis prediction.

4. **Decision Trees**
   - Understand branching logic using questions to split data.
   - Learn metrics like entropy or Gini for choosing splits.
   - Applications: Loan approval, medical condition classification.

5. **Ensemble Methods**
   - Study random forests: multiple trees voting on predictions.
   - Explore boosting (e.g., AdaBoost, Gradient Boosting) for error correction.
   - Use cases: Customer churn prediction, ranking systems.

6. **Support Vector Machines (SVMs)**
   - Learn about hyperplanes and maximizing margins.
   - Understand kernel tricks (e.g., RBF) for non-linear data.
   - Applications: Face recognition, text categorization.

7. **Neural Networks (Basics)**
   - Understand the structure of a neuron: inputs, weights, biases, activation.
   - Learn how neurons combine in layers to process data.
   - Example: Basic prediction tasks with numerical data.

8. **Convolutional Neural Networks (CNNs)**
   - Study convolutional layers and kernels for feature extraction in images.
   - Understand pooling and fully connected layers for final decisions.
   - Applications: Image recognition, object detection.

9. **Fully Connected Neural Networks (FCNNs)**
   - Explore dense layers where all neurons connect to the next layer.
   - Learn their role in combining features for final predictions.
   - Use cases: Non-image data like stock price prediction, text classification.

10. **Vision Transformers (ViTs)**
    - Understand image patches and their transformation into vectors.
    - Learn self-attention mechanisms for weighing important features.
    - Applications: Advanced image classification, medical imaging.